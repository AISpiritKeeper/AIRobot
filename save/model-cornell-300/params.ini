[General]
version = 0.5
globstep = 2100
watsonmode = False
autoencode = False
corpus = cornell

[Dataset]
datasettag = 
maxlength = 10
filtervocab = 0
skiplines = False
vocabularysize = 1000

[Network]
hiddensize = 512
numlayers = 2
softmaxsamples = 0
embeddingsize = 64

[Training (won't be restored)]
learningrate = 0.002
batchsize = 50
dropout = 0.9

